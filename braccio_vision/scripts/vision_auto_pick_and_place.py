#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from geometry_msgs.msg import PointStamped
import time
import math
import numpy as np
import cv2
import json
import os
import sys

# Importar directamente la clase ConfigurablePickAndPlace
sys.path.append('/home/ivan/Escritorio/Braccio-Tinkerkit-Arduino/braccio_vision/scripts')
from pick_and_place_configurable import ConfigurablePickAndPlace

class VisionBasedPickAndPlace(Node):
    def __init__(self):
        super().__init__('vision_based_pick_and_place')
        
        # Crear instancia del nodo de pick and place
        self.pick_and_place_node = ConfigurablePickAndPlace()
        
        # Subscriber para detecci√≥n de objetos
        self.object_subscriber = self.create_subscription(
            PointStamped,
            '/detected_object_coords',
            self.object_detected_callback,
            10
        )
        
        # Configuraci√≥n
        self.detected_objects = []  # Lista de objetos detectados con nombres (pixel_x, pixel_y, model_name)
        self.processed_objects = set()  # Set de objetos ya procesados (model_name)
        self.processing = False
        
        # Cargar homograf√≠a para transformaci√≥n p√≠xel -> mundo
        self.load_homography()
        
        self.get_logger().info('ü§ñ Vision-Based Pick and Place iniciado')
        self.get_logger().info('üëÅÔ∏è  Esperando detecci√≥n de cubos verdes...')
        
        # Timer para verificar detecciones peri√≥dicamente
        self.timer = self.create_timer(1.0, self.check_for_objects)
        
        # Timer para mostrar estad√≠sticas cada 10 segundos
        self.stats_timer = self.create_timer(10.0, self.show_statistics)

    def load_homography(self):
        """Cargar matriz de homograf√≠a para transformaci√≥n p√≠xel -> mundo"""
        try:
            config_path = "/home/ivan/Escritorio/Braccio-Tinkerkit-Arduino/braccio_vision/config/camera_calibration.json"
            with open(config_path, 'r') as f:
                data = json.load(f)
            self.homography_matrix = np.array(data['homography_matrix'])
            self.get_logger().info('‚úÖ Homograf√≠a cargada exitosamente')
            # Debug: mostrar la matriz
            self.get_logger().info(f'üîç Matriz de homograf√≠a: {self.homography_matrix.tolist()}')
        except Exception as e:
            self.homography_matrix = None
            self.get_logger().warn(f'‚ö†Ô∏è  Sin homograf√≠a ({e}) - usando mapeo simple')

    def transform_pixels_to_world(self, pixel_x, pixel_y):
        """Transformar coordenadas de p√≠xeles a coordenadas del mundo real"""
        self.get_logger().info(f'üîÑ TRANSFORMANDO: p√≠xel({pixel_x},{pixel_y}) usando {"HOMOGRAF√çA" if self.homography_matrix is not None else "MAPEO SIMPLE"}')
        
        if self.homography_matrix is not None:
            try:
                # Usar homograf√≠a calibrada
                pixel_point = np.array([[pixel_x, pixel_y]], dtype=np.float32).reshape(-1, 1, 2)
                world_point = cv2.perspectiveTransform(pixel_point, self.homography_matrix)
                x, y = float(world_point[0][0][0]), float(world_point[0][0][1])
                rho = math.sqrt(x**2 + y**2)
                self.get_logger().info(f'üéØ Homograf√≠a: p√≠xel({pixel_x},{pixel_y}) -> mundo({x:.3f},{y:.3f}) rho={rho:.3f}m')
                return x, y
            except Exception as e:
                self.get_logger().error(f'‚ùå Error en homograf√≠a: {e}')
        
        # Mapeo corregido para el workspace real del Braccio
        # Basado en an√°lisis de posiciones reales vs detectadas
        
        # C√°lculo base sin limitaciones restrictivas
        x = (pixel_x - 320) * 0.0008  # Mantener factor de escala
        y = (240 - pixel_y) * 0.0008  # Mantener factor de escala, invertir Y
        
        # Ajuste de offset para centrar en el workspace del Braccio
        x_offset = 0.30  # Mover el origen m√°s lejos de la base (era 0.20)
        y_offset = 0.0   # Sin offset en Y (era 0.20)
        
        x_world = x + x_offset
        y_world = y + y_offset
        
        # L√≠mites ampliados para el workspace real del Braccio
        # Basado en posiciones reales: X=[0.24-0.35], Y=[-0.23, 0.18]
        x_world = max(0.20, min(0.40, x_world))  # Rango ampliado y realista
        y_world = max(-0.25, min(0.20, y_world))  # Rango ampliado y realista
        
        rho = math.sqrt(x_world**2 + y_world**2)
        self.get_logger().info(f'üéØ Mapeo corregido: p√≠xel({pixel_x},{pixel_y}) -> mundo({x_world:.3f},{y_world:.3f}) rho={rho:.3f}m')
        return x_world, y_world

    def object_detected_callback(self, msg):
        """A√±adir nueva detecci√≥n a la lista si no est√° ya presente"""
        pixel_x = int(msg.point.x)
        pixel_y = int(msg.point.y)
        
        # DEBUG: Mostrar exactamente qu√© recibimos
        self.get_logger().info(f'üì® RECIBIDO del object_detector: p√≠xel({pixel_x}, {pixel_y})')
        
        # Verificar si el objeto ya est√° en la lista (evitar duplicados)
        # Usando un umbral de distancia para evitar ruido de detecci√≥n
        threshold = 10  # p√≠xeles de tolerancia
        is_duplicate = False
        
        for existing_x, existing_y, _ in self.detected_objects:
            distance = math.sqrt((pixel_x - existing_x)**2 + (pixel_y - existing_y)**2)
            if distance < threshold:
                is_duplicate = True
                break
        
        if not is_duplicate:
            # Generar nombre de modelo basado en posici√≥n
            model_name = self.determine_model_name(pixel_x, pixel_y)
            
            # Si no se pudo determinar un modelo v√°lido (ya procesado), ignorar
            if model_name is None:
                self.get_logger().info(f'üö´ No se pudo mapear cubo en ({pixel_x}, {pixel_y}) - posiblemente ya procesado')
                return
            
            # Verificar si el objeto ya fue procesado (doble verificaci√≥n)
            if model_name in self.processed_objects:
                self.get_logger().info(f'üö´ Cubo {model_name} ya procesado anteriormente, ignorando...')
                return
            
            self.detected_objects.append((pixel_x, pixel_y, model_name))
            color_type = "verde" if "green" in model_name else "azul" if "blue" in model_name else "desconocido"
            self.get_logger().info(f'üëÅÔ∏è  Nuevo cubo {color_type} detectado: {model_name} en p√≠xeles ({pixel_x}, {pixel_y})')
            self.get_logger().info(f'üìã Total de cubos en lista: {len(self.detected_objects)}')
        else:
            self.get_logger().info(f'üîÑ Objeto duplicado ignorado: p√≠xel({pixel_x}, {pixel_y})')

    def determine_model_name(self, pixel_x, pixel_y):
        """
        Determina el nombre del modelo real m√°s cercano a las coordenadas detectadas.
        Mapea coordenadas detectadas a los nombres reales de los objetos en Gazebo.
        """
        # Convertir coordenadas de p√≠xeles a coordenadas del mundo
        world_x, world_y = self.transform_pixels_to_world(pixel_x, pixel_y)
        
        # Lista de objetos reales con sus posiciones (basada en object_spawner.py)
        real_objects = [
            {"name": "green_cube1", "x": 0.35, "y": 0.05, "z": 0.025},
            {"name": "green_cube2", "x": 0.28, "y": 0.18, "z": 0.025}, 
            {"name": "blue_cube1", "x": 0.28, "y": -0.15, "z": 0.025},
            {"name": "blue_cube2", "x": 0.24, "y": -0.23, "z": 0.025},  
        ]
        
        # Encontrar el objeto m√°s cercano
        min_distance = float('inf')
        closest_object = None
        
        for obj in real_objects:
            # Calcular distancia euclidiana en 2D (X, Y)
            distance = math.sqrt((world_x - obj["x"])**2 + (world_y - obj["y"])**2)
            if distance < min_distance:
                min_distance = distance
                closest_object = obj["name"]
        
        # Verificar que el objeto no est√© ya procesado
        if closest_object in self.processed_objects:
            self.get_logger().warn(f'‚ö†Ô∏è Objeto m√°s cercano {closest_object} ya fue procesado')
            return None
        
        self.get_logger().info(f'üéØ Coordenadas detectadas ({world_x:.3f}, {world_y:.3f}) ‚Üí Objeto real: {closest_object} (distancia: {min_distance:.3f}m)')
        return closest_object

    def check_for_objects(self):
        """Procesar el primer objeto de la lista si no estamos ocupados"""
        if self.detected_objects and not self.processing:
            # Separar verdes y azules
            green_objects = [(x, y, name) for x, y, name in self.detected_objects if 'green' in name]
            blue_objects = [(x, y, name) for x, y, name in self.detected_objects if 'blue' in name]
            # Prioridad: verdes primero
            if green_objects:
                pixel_x, pixel_y, model_name = green_objects[0]
                self.get_logger().info(f'üéØ Procesando cubo verde {model_name} en posici√≥n: ({pixel_x}, {pixel_y})')
                self.get_logger().info(f'üìã Quedan {len(self.detected_objects)-1} cubos en cola')
                self.process_detected_object(pixel_x, pixel_y, model_name)
            elif blue_objects:
                pixel_x, pixel_y, model_name = blue_objects[0]
                self.get_logger().info(f'üéØ Procesando cubo azul {model_name} en posici√≥n: ({pixel_x}, {pixel_y})')
                self.get_logger().info(f'üìã Quedan {len(self.detected_objects)-1} cubos en cola')
                self.process_detected_object(pixel_x, pixel_y, model_name)

    def process_detected_object(self, pixel_x, pixel_y, model_name):
        """Procesar el objeto detectado y ejecutar pick and place"""
        self.processing = True
        try:
            self.get_logger().info(f'üîÑ Procesando objeto {model_name}...')
            # 1. Transformar p√≠xeles a coordenadas del mundo
            object_x, object_y = self.transform_pixels_to_world(pixel_x, pixel_y)
            object_z = 0.025  # Altura real de los cubos spawneados
            
            # Por ahora, usamos las coordenadas originales para el diagn√≥stico
            object_x_corrected = object_x
            object_y_corrected = object_y
            
            self.get_logger().info(f'üìç Objeto {model_name} localizado en: ({object_x:.3f}, {object_y:.3f}, {object_z:.3f})')
            self.get_logger().info(f'üîß Coordenadas para IK: ({object_x_corrected:.3f}, {object_y_corrected:.3f}, {object_z:.3f})')
            
            # 2. Calcular cinem√°tica inversa
            if not self.run_ik_calculation(object_x_corrected, object_y_corrected, object_z):
                self.get_logger().error(f'‚ùå Error en el c√°lculo de cinem√°tica inversa para {model_name}. Pick and place cancelado.')
                print(f"‚ùå Error: {model_name} est√° fuera de alcance o la cinem√°tica ha fallado. Pick and place cancelado.")
                # Eliminar el objeto de la lista aunque falle (objeto inaccesible)
                if self.detected_objects:
                    self.detected_objects.pop(0)
                    self.get_logger().info(f'üóëÔ∏è  {model_name} eliminado de la lista (fuera de alcance)')
                return
            
            # 3. Ejecutar pick and place usando el nodo configurado
            self.get_logger().info(f'ü§ñ Iniciando secuencia pick and place para {model_name}...')
            # Seleccionar secuencia seg√∫n color del cubo
            if "green" in model_name:
                sequence_name = 'green_cube_sequence'
                self.get_logger().info(f'üü¢ Usando secuencia para cubos verdes ‚Üí destino: (0.25, 0.10)')
            elif "blue" in model_name:
                sequence_name = 'blue_cube_sequence'
                self.get_logger().info(f'üîµ Usando secuencia para cubos azules ‚Üí destino: (-0.25, 0.10)')
            else:
                sequence_name = 'basic_demo'  # fallback
                self.get_logger().info(f'‚ö™ Usando secuencia por defecto')

            # Llamar al nodo de pick and place con la secuencia espec√≠fica
            if self.pick_and_place_node.execute_pick_and_place_for_target(model_name, sequence_name):
                self.get_logger().info(f'üéâ ¬°PICK AND PLACE COMPLETADO EXITOSAMENTE PARA {model_name}!')
                # Marcar el objeto como procesado
                self.processed_objects.add(model_name)
                # Eliminar el objeto de la lista tras recogerlo exitosamente
                if self.detected_objects:
                    self.detected_objects.pop(0)
                    self.get_logger().info(f'‚úÖ {model_name} recogido y marcado como procesado')
                    self.get_logger().info(f'üìù Objetos procesados: {list(self.processed_objects)}')
            else:
                self.get_logger().error(f'‚ùå Error en la ejecuci√≥n del pick and place para {model_name}')
                # Tambi√©n eliminar si falla la ejecuci√≥n (evitar bucle infinito)
                if self.detected_objects:
                    self.detected_objects.pop(0)
                    self.get_logger().info('üóëÔ∏è  Objeto eliminado de la lista (error en ejecuci√≥n)')
                    
        except Exception as e:
            self.get_logger().error(f'‚ùå Error procesando objeto: {e}')
            # Eliminar objeto en caso de excepci√≥n
            if self.detected_objects:
                self.detected_objects.pop(0)
                self.get_logger().info('üóëÔ∏è  Objeto eliminado de la lista (excepci√≥n)')
        finally:
            self.processing = False
            if self.detected_objects:
                self.get_logger().info(f'üìã Objetos restantes en cola: {len(self.detected_objects)}')
            else:
                self.get_logger().info('‚úÖ Lista de objetos vac√≠a. Esperando nuevas detecciones...')

    def run_ik_calculation(self, object_x, object_y, object_z):
        """Ejecutar el calculador de cinem√°tica inversa y detectar estrategia"""
        self.get_logger().info('üßÆ Calculando cinem√°tica inversa...')
        
        try:
            # Importar directamente la clase de IK
            sys.path.append('/home/ivan/Escritorio/Braccio-Tinkerkit-Arduino/braccio_vision/scripts')
            from inverse_kinematics_calculator import InverseKinematicsCalculator
            
            # Crear instancia y calcular IK
            ik_calculator = InverseKinematicsCalculator()
            
            # Verificar si las coordenadas est√°n en el workspace
            if not ik_calculator.validate_workspace(object_x, object_y, object_z):
                self.get_logger().error('‚ùå Error: Objeto fuera del workspace v√°lido')
                return False
            
            # Calcular las posiciones de pick
            pick_positions = ik_calculator.calculate_pick_positions(object_x, object_y, object_z, approach_height=0.08)
            
            if pick_positions is None:
                self.get_logger().error('‚ùå Error: No se pudieron calcular las posiciones de pick')
                return False
            
            # DIAGN√ìSTICO: Mostrar posiciones calculadas
            self.get_logger().info(f'üßÆ DIAGN√ìSTICO - Posiciones IK calculadas para ({object_x:.3f}, {object_y:.3f}, {object_z:.3f}):')
            if 'pick_approach' in pick_positions:
                self.get_logger().info(f'   üìç Pick approach: {[round(x, 4) for x in pick_positions["pick_approach"]]}')
            if 'pick_position' in pick_positions:
                self.get_logger().info(f'   üìç Pick position: {[round(x, 4) for x in pick_positions["pick_position"]]}')
            
            # Verificar que las posiciones son diferentes para objetos diferentes
            if hasattr(self, 'last_pick_positions'):
                if (pick_positions.get('pick_approach') == self.last_pick_positions.get('pick_approach') and
                    pick_positions.get('pick_position') == self.last_pick_positions.get('pick_position')):
                    self.get_logger().warn('‚ö†Ô∏è  ALERTA: Las posiciones IK son id√©nticas al objeto anterior!')
                else:
                    self.get_logger().info('‚úÖ Las posiciones IK son diferentes al objeto anterior')
            self.last_pick_positions = pick_positions.copy()
            
            # Guardar las posiciones en el archivo de configuraci√≥n
            config_path = '/home/ivan/Escritorio/Braccio-Tinkerkit-Arduino/braccio_moveit_config/config/pick_and_place_config.yaml'
            
            if ik_calculator.save_positions_to_config(pick_positions, config_path):
                self.get_logger().info('‚úÖ Cinem√°tica inversa calculada y configuraci√≥n guardada exitosamente')
                # CR√çTICO: Tiempo adicional para asegurar escritura completa y estabilizaci√≥n
                self.get_logger().info('‚è≥ Esperando estabilizaci√≥n del archivo de configuraci√≥n...')
                time.sleep(1.0)  # Tiempo aumentado para evitar problemas de sincronizaci√≥n
                return True
            else:
                self.get_logger().error('‚ùå Error: No se pudo guardar la configuraci√≥n')
                return False
                
        except Exception as e:
            self.get_logger().error(f'‚ùå Error ejecutando calculador de IK: {e}')
            return False

    def show_statistics(self):
        """Mostrar estad√≠sticas del sistema cada 10 segundos"""
        if self.processed_objects:
            self.get_logger().info(f'üìä ESTAD√çSTICAS: {len(self.processed_objects)} objetos procesados: {list(self.processed_objects)}')
        else:
            self.get_logger().info('üìä ESTAD√çSTICAS: Ning√∫n objeto procesado a√∫n')
        
        if self.detected_objects:
            self.get_logger().info(f'üìä ESTAD√çSTICAS: {len(self.detected_objects)} objetos en cola de procesamiento')

    def reset_processed_objects(self):
        """Resetear la lista de objetos procesados (√∫til para pruebas)"""
        self.processed_objects.clear()
        self.get_logger().info('üîÑ Lista de objetos procesados reseteada')

def main(args=None):
    rclpy.init(args=args)
    
    try:
        node = VisionBasedPickAndPlace()
        
        print("\nü§ñ VISION-BASED PICK AND PLACE")
        print("="*50)
        print("üëÅÔ∏è  Escuchando detecciones de cubos verdes...")
        print("üìã Procesar√° m√∫ltiples objetos en orden de detecci√≥n")
        print("üéØ Destino: Configurado en pick_and_place_config.yaml")
        print("üõë Ctrl+C para detener")
        print("="*50)
        
        # Ejecutar el nodo
        rclpy.spin(node)
        
    except KeyboardInterrupt:
        print("\nüëã Detenido por el usuario")
    except Exception as e:
        print(f"‚ùå Error: {e}")
    finally:
        if 'node' in locals():
            node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
