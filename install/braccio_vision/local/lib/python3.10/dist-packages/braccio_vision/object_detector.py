#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
import cv2
import numpy as np
import yaml
import os
from ament_index_python.packages import get_package_share_directory

from sensor_msgs.msg import Image, CameraInfo
from geometry_msgs.msg import Point, PointStamped
from std_msgs.msg import Header, ColorRGBA
from visualization_msgs.msg import Marker, MarkerArray
from cv_bridge import CvBridge

class ObjectDetector(Node):
    def __init__(self):
        super().__init__('object_detector')
        
        # Cargar configuraciÃ³n
        self.load_config()
        
        # Bridge para convertir imÃ¡genes
        self.bridge = CvBridge()
        
        # Variables de estado
        self.camera_info = None
        self.latest_image = None
        
        # Subscribers
        self.image_subscriber = self.create_subscription(
            Image,
            self.config['camera']['topic_image'],
            self.image_callback,
            10
        )
        
        self.camera_info_subscriber = self.create_subscription(
            CameraInfo,
            self.config['camera']['topic_camera_info'],
            self.camera_info_callback,
            10
        )
        
        # Publishers
        self.debug_image_publisher = self.create_publisher(
            Image,
            self.config['publishing']['debug_image_topic'],
            10
        )
        
        self.marker_publisher = self.create_publisher(
            MarkerArray,
            self.config['publishing']['object_markers_topic'],
            10
        )
        
        # Publisher para coordenadas del objeto detectado (CRÃTICO para pick and place)
        self.coords_publisher = self.create_publisher(
            PointStamped,
            '/detected_object_coords',
            10
        )
        
        # Timer para procesamiento
        detection_rate = self.config['publishing']['detection_rate']
        self.detection_timer = self.create_timer(
            1.0 / detection_rate,
            self.process_detection
        )
        
        self.get_logger().info('ðŸ” Object Detector iniciado')
        self.get_logger().info(f'ðŸ“· Escuchando imagen en: {self.config["camera"]["topic_image"]}')

    def load_config(self):
        """Carga la configuraciÃ³n desde el archivo YAML"""
        try:
            pkg_share = get_package_share_directory('braccio_vision')
            config_path = os.path.join(pkg_share, 'config', 'vision_config.yaml')
            
            if not os.path.exists(config_path):
                config_path = '/home/ivan/Escritorio/Braccio-Tinkerkit-Arduino/braccio_vision/config/vision_config.yaml'
            
            with open(config_path, 'r') as file:
                self.config = yaml.safe_load(file)
            
            self.get_logger().info(f'âœ… ConfiguraciÃ³n cargada desde: {config_path}')
            
        except Exception as e:
            self.get_logger().error(f'âŒ Error cargando configuraciÃ³n: {str(e)}')
            # ConfiguraciÃ³n mÃ­nima por defecto
            self.config = self.get_default_config()

    def get_default_config(self):
        """ConfiguraciÃ³n por defecto"""
        return {
            'camera': {
                'topic_image': '/overhead_camera/image_raw',
                'topic_camera_info': '/overhead_camera/camera_info'
            },
            'publishing': {
                'debug_image_topic': '/vision/debug_image',
                'object_markers_topic': '/vision/object_markers',
                'detection_rate': 10.0
            },
            'object_detection': {
                'red_object': {
                    'enabled': True,
                    'hsv_lower': [0, 120, 70],
                    'hsv_upper': [10, 255, 255],
                    'min_area': 100,
                    'max_area': 5000
                }
            },
            'workspace': {
                'camera_height': 1.0
            }
        }

    def image_callback(self, msg):
        """Callback para recibir imÃ¡genes"""
        try:
            self.latest_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except Exception as e:
            self.get_logger().error(f'Error convertir imagen: {str(e)}')

    def camera_info_callback(self, msg):
        """Callback para informaciÃ³n de la cÃ¡mara"""
        if self.camera_info is None:
            self.camera_info = msg
            self.get_logger().info('ðŸ“· InformaciÃ³n de cÃ¡mara recibida')

    def detect_objects_by_color(self, image):
        """Detecta objetos por color HSV"""
        detected_objects = []
        
        # Convertir a HSV
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # Crear imagen de debug
        debug_image = image.copy()
        
        # Detectar cada tipo de objeto configurado
        for obj_name, obj_config in self.config['object_detection'].items():
            if not obj_config.get('enabled', False):
                continue
            
            # Crear mÃ¡scara de color
            lower = np.array(obj_config['hsv_lower'])
            upper = np.array(obj_config['hsv_upper'])
            mask = cv2.inRange(hsv, lower, upper)
            
            # Aplicar filtros morfolÃ³gicos
            kernel = np.ones((5, 5), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            
            # Encontrar contornos
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                
                # Filtrar por Ã¡rea
                if (area >= obj_config['min_area'] and 
                    area <= obj_config['max_area']):
                    
                    # Calcular centro del objeto
                    M = cv2.moments(contour)
                    if M["m00"] != 0:
                        cx = int(M["m10"] / M["m00"])
                        cy = int(M["m01"] / M["m00"])
                        
                        # Convertir pÃ­xeles a coordenadas del mundo
                        world_x, world_y = self.pixel_to_world(cx, cy)
                        
                        detected_objects.append({
                            'name': obj_name,
                            'pixel_x': cx,
                            'pixel_y': cy,
                            'world_x': world_x,
                            'world_y': world_y,
                            'area': area,
                            'contour': contour
                        })
                        
                        # Dibujar en imagen de debug
                        cv2.drawContours(debug_image, [contour], -1, (0, 255, 0), 2)
                        cv2.circle(debug_image, (cx, cy), 5, (255, 0, 0), -1)
                        cv2.putText(debug_image, f'{obj_name}', 
                                   (cx - 50, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 
                                   0.5, (255, 255, 255), 2)
                        cv2.putText(debug_image, f'({world_x:.2f}, {world_y:.2f})', 
                                   (cx - 50, cy + 20), cv2.FONT_HERSHEY_SIMPLEX, 
                                   0.4, (255, 255, 255), 1)
        
        return detected_objects, debug_image

    def pixel_to_world(self, pixel_x, pixel_y):
        """Convierte coordenadas de pÃ­xel a coordenadas del mundo"""
        if self.camera_info is None:
            # Usar valores por defecto
            cx = self.config['camera']['width'] / 2
            cy = self.config['camera']['height'] / 2
            fx = 554.0  # Valor aproximado
            fy = 554.0
        else:
            # Usar parÃ¡metros de la cÃ¡mara
            cx = self.camera_info.k[2]  # Principal point x
            cy = self.camera_info.k[5]  # Principal point y
            fx = self.camera_info.k[0]  # Focal length x
            fy = self.camera_info.k[4]  # Focal length y
        
        # Calcular coordenadas del mundo usando geometrÃ­a de cÃ¡mara cenital
        camera_height = self.config['workspace']['camera_height']
        
        # Coordenadas normalizadas
        x_norm = (pixel_x - cx) / fx
        y_norm = (pixel_y - cy) / fy
        
        # ProyecciÃ³n al plano Z=0 (mesa)
        world_x = x_norm * camera_height
        world_y = y_norm * camera_height
        
        return world_x, world_y

    def create_object_markers(self, detected_objects):
        """Crea markers de visualizaciÃ³n para los objetos detectados"""
        marker_array = MarkerArray()
        
        for i, obj in enumerate(detected_objects):
            marker = Marker()
            marker.header.frame_id = "world"
            marker.header.stamp = self.get_clock().now().to_msg()
            marker.id = i
            marker.type = Marker.CYLINDER
            marker.action = Marker.ADD
            
            # PosiciÃ³n
            marker.pose.position.x = obj['world_x']
            marker.pose.position.y = obj['world_y']
            marker.pose.position.z = 0.025  # Altura del marker
            marker.pose.orientation.w = 1.0
            
            # TamaÃ±o
            marker.scale.x = 0.05
            marker.scale.y = 0.05
            marker.scale.z = 0.05
            
            # Color segÃºn el tipo de objeto
            if 'red' in obj['name']:
                marker.color = ColorRGBA(r=1.0, g=0.0, b=0.0, a=0.8)
            elif 'green' in obj['name']:
                marker.color = ColorRGBA(r=0.0, g=1.0, b=0.0, a=0.8)
            elif 'blue' in obj['name']:
                marker.color = ColorRGBA(r=0.0, g=0.0, b=1.0, a=0.8)
            else:
                marker.color = ColorRGBA(r=1.0, g=1.0, b=0.0, a=0.8)
            
            marker.lifetime.sec = 1  # DuraciÃ³n del marker
            marker_array.markers.append(marker)
        
        return marker_array

    def process_detection(self):
        """Procesa la detecciÃ³n de objetos"""
        if self.latest_image is None:
            return
        
        try:
            # Detectar objetos
            detected_objects, debug_image = self.detect_objects_by_color(self.latest_image)
            
            # Publicar imagen de debug
            debug_msg = self.bridge.cv2_to_imgmsg(debug_image, "bgr8")
            debug_msg.header.stamp = self.get_clock().now().to_msg()
            debug_msg.header.frame_id = self.config['camera']['frame_id']
            self.debug_image_publisher.publish(debug_msg)
            
            # Publicar markers
            if detected_objects:
                markers = self.create_object_markers(detected_objects)
                self.marker_publisher.publish(markers)
                
                # Publicar coordenadas del primer objeto detectado (para pick and place)
                first_object = detected_objects[0]  # Tomar el primer objeto detectado
                coords_msg = PointStamped()
                coords_msg.header.stamp = self.get_clock().now().to_msg()
                coords_msg.header.frame_id = self.config['camera']['frame_id']
                coords_msg.point.x = first_object['world_x']
                coords_msg.point.y = first_object['world_y']
                coords_msg.point.z = 0.0  # Altura del plano de trabajo
                self.coords_publisher.publish(coords_msg)
                
                # Log de objetos detectados
                for obj in detected_objects:
                    self.get_logger().info(
                        f'ðŸŽ¯ {obj["name"]}: ({obj["world_x"]:.3f}, {obj["world_y"]:.3f})'
                    )
            
        except Exception as e:
            self.get_logger().error(f'Error en detecciÃ³n: {str(e)}')

def main(args=None):
    rclpy.init(args=args)
    
    try:
        node = ObjectDetector()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        if 'node' in locals():
            node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
